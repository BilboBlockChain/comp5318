{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Forest Fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set a reproducible seed and separate out the target feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "\n",
    "raw = pd.read_csv('forestfires.csv')\n",
    "\n",
    "# subset X columns and Y column\n",
    "X = raw.iloc[:, 0:12]\n",
    "y = np.array(raw.iloc[:, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then perform the sine cosine feature transformation of the month and day features by first mapping them to sequential numerics and then generating the following features for each of them:\n",
    "$$x_{\\sin }=\\sin \\left(\\frac{2 * \\pi * x}{\\max (x)}\\right)$$\n",
    "\n",
    "$$x_{\\cos }=\\cos \\left(\\frac{2 * \\pi * x}{\\max (x)}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# cos sin transform categorical sequential features\n",
    "# map features to numerics\n",
    "monthDict = dict(zip(['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'],[1,2,3,4,5,6,7,8,9,10,11,12]))\n",
    "dayDict = dict(zip(['mon','tue','wed','thu','fri','sat','sun'],[1,2,3,4,5,6,7]))\n",
    "\n",
    "X['month'] = X['month'].map(monthDict).astype(float)\n",
    "X['day'] = X['day'].map(dayDict).astype(float)\n",
    "\n",
    "\n",
    "# map each cyclical variable onto a circle so lowest value for that variable appears right next to the largest value.\n",
    "X['day_sin'] = np.sin(X.day*(2.*np.pi/7))\n",
    "X['day_cos'] = np.cos(X.day*(2.*np.pi/7))\n",
    "X['mnth_sin'] = np.sin(X.month*(2.*np.pi/12))\n",
    "X['mnth_cos'] = np.cos(X.month*(2.*np.pi/12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we drop the original month and day features and convert the ints to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original categorical variables\n",
    "X = X.drop(['month', 'day'], 1)\n",
    "\n",
    "# fix int warning\n",
    "X['X'] = X['X'].astype(float)\n",
    "X['Y'] = X['Y'].astype(float)\n",
    "X['RH'] = X['RH'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the negative log likelihood function as follows:\n",
    "$$N N L=-\\log p\\left(y_{*} | D, x_{*}\\right)=\\frac{1}{2} \\log \\left(2 \\pi \\sigma_{*}^{2}\\right)+\\frac{\\left(y_{*}-\\bar{f}\\left(x_{*}\\right)\\right)^{2}}{2 \\sigma_{*}^{2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define negative log likelihood of sample\n",
    "def negative_log_likelihood(y, p):\n",
    "    result = 0.5 * np.log(2 * np.pi * np.var(p)) + (((y - np.mean(p)) ** 2) / (2 * np.var(p)))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature sets to tune over in the inner fold are then defined. We utilise the four sets from the original paper and the additional complete set of all features: *STFWIM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection list\n",
    "STFWIM = ['X', 'Y', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain',\n",
    "       'day_sin', 'day_cos', 'mnth_sin', 'mnth_cos']\n",
    "\n",
    "STFWI = ['X', 'Y', 'FFMC', 'DMC', 'DC', 'ISI', 'day_sin', 'day_cos', 'mnth_sin', 'mnth_cos']\n",
    "\n",
    "STM = ['X', 'Y', 'temp', 'RH', 'wind', 'rain', 'day_sin', 'day_cos', 'mnth_sin', 'mnth_cos']\n",
    "\n",
    "FWI = ['FFMC', 'DMC', 'DC', 'ISI']\n",
    "\n",
    "M = ['temp', 'RH', 'wind', 'rain']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we define the nested cross validation function. \n",
    "First, a pipeline of the preprocessing steps is created to be reused in all folds. We then explicitly set the 10 outer and inner folds with a seed for reproducibility. \n",
    "\n",
    "We utilise sklearns GridSearchCV for the hyperparamater search of the inner fold, and take advantage of its multithreading to speed up the process\n",
    "\n",
    "The list of outer fold reuslts to persist, inner fold results to pass to the outer fold and feature spaces to tune are then created. \n",
    "The outer loop splits test and train data, sending the train data into the inner loop for CV. The inner loop fits and validates models on the train folds of the outer kv whilst looping through the feature sets. The best of the models, evaluated by the argmax NMSE is then persisted, with its parameter values and feature set saved to be fitted on train and evaluated on outer test.\n",
    "\n",
    "Score metrics and output results are then retrieved from the outer fold and persisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def nested_crossval(model , parameters):\n",
    "    # build pipeline\n",
    "    pipeline = Pipeline([('scaler', MinMaxScaler()),\n",
    "                         ('estimator',\n",
    "                          TransformedTargetRegressor(regressor=model\n",
    "                                                     , func=np.log1p, inverse_func=np.expm1))])\n",
    "\n",
    "    # define outer and inner folds\n",
    "    outer_kv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    inner_kv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    \n",
    "    #instantiate inner CV grid search \n",
    "    cv = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=inner_kv,\n",
    "                      scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=True)\n",
    "    \n",
    "    #create list of feature spaces to search and list of result to persist\n",
    "    feature_space = [STFWIM, STFWI, STM, FWI, M]\n",
    "    inner_result = []\n",
    "    outer_result = []\n",
    "    saving_inner_results = []\n",
    "    i = 0\n",
    "    for train, test in outer_kv.split(X):\n",
    "        print(\"run\", i)\n",
    "        # loop over feature space using only training data and cross validator hyper param tuner\n",
    "        for f in feature_space:\n",
    "            cv.fit(X.loc[X.index[train], f], y[train])\n",
    "            # persist models to fit best on training set\n",
    "            inner_result.append([cv, cv.best_params_, f, cv.best_score_])\n",
    "            print(f)\n",
    "            print(cv.best_score_)\n",
    "        # persits and reset inner result for next fold\n",
    "        inner_df = pd.DataFrame(inner_result)\n",
    "        # reset inner result\n",
    "        inner_result = []\n",
    "        # receive best model of run to fit on test set\n",
    "        best_params_arg = inner_df.loc[:, 3].argmax()\n",
    "        best_params = inner_df.iloc[best_params_arg, :]\n",
    "        # fit best cv model hyper parameters on best feature set for that fold\n",
    "        bcv = best_params[0]\n",
    "        bfs = best_params[2]\n",
    "        bcv.fit(X.loc[X.index[train], bfs], y[train])\n",
    "\n",
    "        # get training/val and test scores\n",
    "        train_score = best_params[3]\n",
    "        test_score = bcv.score(X.loc[X.index[test], bfs], y[test])\n",
    "\n",
    "        # get predictions and retrieve nll of test folds\n",
    "        y_preds = cv.predict(X.loc[X.index[test], bfs])\n",
    "        mae = mean_absolute_error(y[test], y_preds)\n",
    "        nllval = negative_log_likelihood(y[test], y_preds)\n",
    "        mean_nll = np.mean(nllval)\n",
    "\n",
    "        outer_result.append([i, train_score, test_score, mae, bfs, best_params[1], y[test], nllval, mean_nll])\n",
    "        i += 1\n",
    "\n",
    "    testing = pd.DataFrame(outer_result)\n",
    "    testing.columns = ['fold_number', 'train_nmse', 'test_nmse', 'test_mae', 'best_feature_set', 'best_hyperparams',\n",
    "                       'test_set', 'nll', 'mean_nll']\n",
    "\n",
    "    return testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model on the SVM with its hyperparameters and time the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "\n",
    "svr_results = nested_crossval(SVR(),\n",
    "                        {'estimator__regressor__C': [1, 10, 100, 1000],\n",
    "                         'estimator__regressor__kernel': ['linear', 'rbf']})\n",
    "\n",
    "print(\"average SVM test fold RMSE:\", np.sqrt(np.mean(np.negative(svr_results['test_nmse']))))\n",
    "print(\"average SVM test fold MSE:\",np.mean(np.negative(svr_results['test_nmse'])))\n",
    "print(\"average SVM test fold MAE (MAD):\", np.mean(svr_results['test_mae']))\n",
    "print(\"average SVM test fold NLL:\", np.mean(svr_results['mean_nll']))\n",
    "\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then on the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results = nested_crossval(SGDRegressor(max_iter=5, tol=-np.infty, random_state=42),\n",
    "                       [{\"estimator__regressor__penalty\": [None]},\n",
    "             {\"estimator__regressor__penalty\": ['l2', 'l1'],\"estimator__regressor__alpha\": [1e-5,1e-4,1e-3,1e-2,1e-1]},\n",
    "             {\"estimator__regressor__penalty\": ['elasticnet'],\"estimator__regressor__alpha\": [1e-5,1e-4,1e-3,1e-2,1e-1],\n",
    "              \"estimator__regressor__l1_ratio\": [0.001, 0.25, 0.5, 0.75, 0.999]}])\n",
    "\n",
    "print(\"average LR test fold RMSE:\", np.sqrt(np.mean(np.negative(lr_results['test_nmse']))))\n",
    "print(\"average LR test fold MSE:\",np.mean(np.negative(lr_results['test_nmse'])))\n",
    "print(\"average LR test fold MAE (MAD):\", np.mean(lr_results['test_mae']))\n",
    "print(\"average LR test fold NLL:\", np.mean(lr_results['mean_nll']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally on the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = nested_crossval(RandomForestRegressor(random_state=42),\n",
    "                       {\"Random Forest__regressor__n_estimators\": [500],\n",
    "              \"Random Forest__regressor__max_depth\": [4, 8, 16, None],\n",
    "             \"Random Forest__regressor__min_samples_split\": [2, 4, 6]\n",
    "              })\n",
    "\n",
    "print(\"average RF test fold RMSE:\", np.sqrt(np.mean(np.negative(rf_results['test_nmse']))))\n",
    "print(\"average RF test fold MSE:\",np.mean(np.negative(rf_results['test_nmse'])))\n",
    "print(\"average RF test fold MAE (MAD):\", np.mean(rf_results['test_mae']))\n",
    "print(\"average RF test fold NLL:\", np.mean(rf_results['mean_nll']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
