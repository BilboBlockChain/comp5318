{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5318 - Machine Learning and Data Mining \n",
    "\n",
    "## Tutorial 3 - Linear regression and Gradient Decent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semester 2, 2019**\n",
    "\n",
    "**Objectives:**\n",
    "* To learn how to build a linear regression model from scratch\n",
    "* To learn about Gradient decent\n",
    "* To learn how to use pandas and numpy to preprocess data.\n",
    "\n",
    "**Instructions:**\n",
    "* Exercises to be completed on IPython notebook such as: \n",
    "   * Ipython 3 (Jupyter) notebook installed on your computer http://jupyter.org/install (you need to have Python installed first https://docs.python.org/3/using/index.html )\n",
    "   * Web-based Ipython notebooks such as Google Colaboratory https://colab.research.google.com/ \n",
    "   \n",
    "* If you are using Jupyter intalled on your computer, Go to File->Open. Drag and drop \"lab3.ipynb\" file to the home interface and click upload. \n",
    "* If you are using Google Colaboratory, Click File->Upload notebook, and and upload \"lab3.ipynb\" file\n",
    "* Complete exercises in \"lab3.ipynb\".\n",
    "* To run the cell you can press Ctrl-Enter or hit the Play button at the top.\n",
    "* Complete all exercises marked with **TODO**.\n",
    "* Save your file when you are done with the exercises, so you can show your tutor next week.\n",
    "\n",
    "Lecturers: Nguyen Hoang Tran \n",
    "\n",
    "Tutors: Fengxiang He, Shaojun Zhang, Fangzhou Shi, Yang Lin, Iwan Budiman, Zhiyi Wang, Canh Dinh, Yixuan Zhang, Rui Dong, Haoyu He, Dai Hoang Tran"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. House Prices Dataset\n",
    "**Dataset descriptions:**\n",
    "* train.csv - the training set\n",
    "* test.csv - the test set\n",
    "* data_description.txt - full description of each column, originally prepared by Dean De Cock but lightly edited to match the column names used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "print(os.listdir(\"./data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries and data...\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "data = pd.read_csv('./data/train.csv')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this tutorial we only consider one feature the Living Area to predict the Sale Price with the expectation that the Price will increase when the Living Area increases.\n",
    "However we can use more features like the number of bedroom...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = data[['GrLivArea','SalePrice']]\n",
    "print(newData.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the dataset on firgure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as pl\n",
    "%matplotlib inline\n",
    "#Grab the relevant data, scale the predictor variable, and add a column of 1s for the gradient descent...\n",
    "\n",
    "x = newData['GrLivArea']\n",
    "y = newData['SalePrice']\n",
    "\n",
    "# Todo: Normalize feature X:\n",
    "x =\n",
    "\n",
    "x = np.c_[np.ones(x.shape[0]), x] \n",
    "pl.scatter(x[:,1], y,marker='.', color = 'r', label = 'Training samples')\n",
    "pl.xlabel('Living Area in square feet (normalised)')\n",
    "pl.ylabel('Sale Price ($)')\n",
    "pl.legend(loc='lower right')\n",
    "plt.title('Sale Price vs Living Area')\n",
    "pl.grid()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building Linear Regression model using Gradient Decent with sum square error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Linear Model:\n",
    "* input: $x \\in R^D$ (covariates, predictors, features, etc)\n",
    "* Output: $y \\in R$ (responses, targets, outcomes, outputs, etc)\n",
    "* Model: $f: x \\to y$,with $f(x)=w_0+ \\\n",
    "\\sum_{d=1}^{D}w_dx_d =w_0+w^T x.$\n",
    "\n",
    "Minimize the Residual sum of squares:\n",
    "$ RSS(w) = \\sum_{n=1}^{N}[y_n-f(x_n)]^2 =  \\sum_{n=1}^{N}[y_n- (w_0 + \\sum_{d=1}^{D}w_dx_{nd}) ]^2 .$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Gradient decent:\n",
    "* Initialize $w =  w^{(0)}$ randomly:\n",
    "* Choose learning rate $ \\eta> 0$\n",
    "*  Loop until convergence:\n",
    "\n",
    "    Compute Gradient: $\\nabla RSS(w) = X^T(Xw^t-y)$\n",
    "    \n",
    "    Update parameters: $w^{t+1} = w^t - \\eta * \\nabla RSS(w)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRADIENT DESCENT\n",
    "def gradient_descent(x, y, w, iterations, eta):\n",
    "    past_loss = []\n",
    "    past_w = [w]\n",
    "    n = y.size\n",
    "    for i in range(iterations):\n",
    "        prediction = np.dot(x, w)\n",
    "        error = prediction - y\n",
    "        loss = 1/(2*n) * np.dot(error.T, error)\n",
    "        past_loss.append(loss)\n",
    "        \n",
    "        # Todo : Caculate Residual sum of squares error following notation on 2.1\n",
    "        GradRss =\n",
    "        # Todo: Cacualte new weight update.\n",
    "        w = \n",
    "        past_w.append(w)\n",
    "        \n",
    "    return past_w, past_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass the relevant variables to the function and get the new values back...\n",
    "eta = 0.01 #Step size\n",
    "iterations = 2000 #No. of iterations\n",
    "np.random.seed(123) #Set the seed\n",
    "w0 = np.random.rand(2) #Pick some random values to start with\n",
    "past_w, past_loss = gradient_descent(x, y, w0, iterations, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the cost function...\n",
    "plt.title('Loss Function')\n",
    "plt.xlabel('No. of iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.plot(past_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(past_w[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. The changing of model through each interation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animation\n",
    "#Set the plot up,\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.title('Sale Price vs Living Area')\n",
    "plt.xlabel('Living Area in square feet (normalised)')\n",
    "plt.ylabel('Sale Price ($)')\n",
    "plt.scatter(x[:,1], y, color='red')\n",
    "line, = ax.plot([], [], lw=2)\n",
    "annotation = ax.text(-1, 700000, '')\n",
    "annotation.set_animated(True)\n",
    "plt.close()\n",
    "\n",
    "#Generate the animation data,\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    annotation.set_text('')\n",
    "    return line, annotation\n",
    "\n",
    "# animation function.  This is called sequentially\n",
    "def animate(i):\n",
    "    x = np.linspace(-5, 20, 1000)\n",
    "    y = past_w[i][1]*x + past_w[i][0]\n",
    "    line.set_data(x, y)\n",
    "    annotation.set_text('loss = %.2f e10' % (past_loss[i]/10000000000))\n",
    "    return line, annotation\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=300, interval=0, blit=True)\n",
    "\n",
    "anim.save('animation.gif', writer='imagemagick', fps = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the animation...\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "filename = 'animation.gif'\n",
    "\n",
    "video = io.open(filename, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4: Using more features to predict the house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For example using LotFrontage, and GrLivArea\n",
    "dataNew = data[[\"GrLivArea\",\"LotFrontage\",'SalePrice']]\n",
    "\n",
    "#remove null value\n",
    "dataNew = dataNew[dataNew['GrLivArea'].notnull()]\n",
    "dataNew = dataNew[dataNew['LotFrontage'].notnull()]\n",
    "\n",
    "x = dataNew[[\"GrLivArea\",\"LotFrontage\"]]\n",
    "y = dataNew['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Todo: \n",
    "#Draw model using New features and plot the gradient loss "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
